#!/usr/bin/env bash
#
# ai-env-doctor: AI Environment Maintenance & Health Check Tool (Optimized)
#
# A comprehensive utility to back up configuration, clean temporary caches,
# and verify repository and application URLs for a local AI development environment.

# Strict mode for safer execution
set -Eeuo pipefail

# ---------- DEFAULT CONFIGURATION ----------
# These values can be overridden by creating a file at ~/.ai_maintenance.conf
REPL_FILES=("$HOME/.bashrc" "$HOME/.zshrc" "$HOME/.ai_repl.sh" "$HOME/.ai_live.sh" "$HOME/.ai_full_repl.sh")
TEMP_DIRS=("$HOME/.ai_temp" "$HOME/.ai_cache" "$HOME/downloads/ai_models_temp")
CRITICAL_URLS=(
    "https://ai.studio/apps/bundled/live_audio"
    "https://ai.studio/apps/bundled/promptdj"
)
EXCLUDED_DOMAINS=("google.com" "microsoft.com" "schema.org" "apple.com")
BACKUP_BASE_DIR="$HOME/.ai_backups"

# ---------- SCRIPT SETUP & LOGGING ----------
# --- Colors (check for TTY and NO_COLOR) ---
if [[ -t 1 && -z "${NO_COLOR:-}" ]]; then
    C_GREEN='\033[0;32m'; C_RED='\033[0;31m'; C_YELLOW='\033[0;33m'
    C_BLUE='\033[0;34m'; C_CYAN='\033[0;36m'; C_NC='\033[0m'
else
    C_GREEN=''; C_RED=''; C_YELLOW=''; C_BLUE=''; C_CYAN=''; C_NC=''
fi

# --- Globals ---
BACKUP_ARCHIVE_NAME="ai_env_backup_$(date +%Y%m%d-%H%M%S).tar.gz"
STAGING_DIR="" # Will be created by mktemp
LOG_FILE=""
declare -A URL_STATUS # Associative array for URL health
FORCE_MODE=0
RUN_BACKUP=0; RUN_CLEAN=0; RUN_CHECK=0

# --- Core Utility Functions ---
# Master log function: prints to console and appends to the log file.
log() {
    local color="$1" message="$2"
    # The tee command handles writing to the log file.
    printf "${color}[%s]${C_NC} %s\n" "$(date +'%T')" "$message"
}

# Fatal error handler
die() {
    log "$C_RED" "FATAL: $1" | tee -a "${LOG_FILE:-/dev/null}"
    exit 1
}

# Create staging directory and log file
setup_staging() {
    STAGING_DIR=$(mktemp -d)
    LOG_FILE="$STAGING_DIR/maintenance_run.log"
    # Redirect all script output to both console and log file
    exec &> >(tee -a "$LOG_FILE")
}

# Cleanup function to remove the temporary backup directory on exit.
cleanup() {
  [[ -n "$STAGING_DIR" ]] && rm -rf "$STAGING_DIR"
}
trap cleanup EXIT

# ---------- HELP & USAGE ----------
show_help() {
    # Using a here document for cleaner formatting
    cat << EOF
${C_GREEN}AI Environment Maintenance & Health Check Tool${C_NC}
Usage: $0 [options]

${C_YELLOW}Options:${C_NC}
  --backup          Run the backup process only.
  --clean           Run the cleanup process only.
  --check           Run the URL health check only.
  --full            Run all processes (default behavior).
  -f, --force       Skip the interactive confirmation prompt for cleaning.
  --no-color        Disable colored output.
  -h, --help        Display this help message.

${C_YELLOW}Configuration:${C_NC}
  Override defaults by creating a configuration file at ${C_CYAN}~/.ai_maintenance.conf${C_NC}
EOF
}

# ---------- CORE FUNCTIONS ----------

check_dependencies() {
    for cmd in "curl" "grep" "tar"; do
        command -v "$cmd" &> /dev/null || die "Required command '$cmd' is not installed."
    done
}

create_backup_archive() {
    log "$C_BLUE" "Starting backup process..."
    
    local files_to_backup=()
    for file in "${REPL_FILES[@]}"; do
        if [[ -f "$file" ]]; then
            log "$C_CYAN" "  -> Queuing $file for backup."
            files_to_backup+=("$file")
        else
            log "$C_YELLOW" "  -> Skipping non-existent file: $file"
        fi
    done

    if [[ ${#files_to_backup[@]} -eq 0 ]]; then
        log "$C_YELLOW" "No files found to back up. Skipping archive creation."
        return
    fi

    mkdir -p "$BACKUP_BASE_DIR"
    local final_archive_path="$BACKUP_BASE_DIR/$BACKUP_ARCHIVE_NAME"
    
    log "$C_BLUE" "Compressing backup files..."
    # Use tar's -C option to control paths inside the archive
    # Using --files-from=- is efficient for a large number of files
    printf "%s\n" "${files_to_backup[@]}" | tar -czf "$final_archive_path" --files-from=- --transform='s|.*/||'
    log "$C_GREEN" "Successfully created backup: $final_archive_path"
}

clean_directories() {
    log "$C_BLUE" "Starting cleanup process..."
    
    local dirs_to_clean=()
    for dir in "${TEMP_DIRS[@]}"; do
        [[ -d "$dir" ]] && dirs_to_clean+=("$dir")
    done

    if [[ ${#dirs_to_clean[@]} -eq 0 ]]; then
        log "$C_YELLOW" "No temporary directories found to clean."
        return
    fi
    
    echo "The following directories are configured for deletion:"
    printf "  - ${C_YELLOW}%s${C_NC}\n" "${dirs_to_clean[@]}"

    if [[ "$FORCE_MODE" -eq 0 ]]; then
        read -p "Are you sure you want to permanently delete these directories? (y/N) " -n 1 -r
        echo
        [[ ! "$REPLY" =~ ^[Yy]$ ]] && { log "$C_RED" "Cleanup aborted by user."; return; }
    fi

    for dir in "${dirs_to_clean[@]}"; do
        log "$C_YELLOW" "  -> Removing $dir"
        rm -rf "$dir"
    done
    
    log "$C_GREEN" "Cleanup complete. Removed ${#dirs_to_clean[@]} director(y/ies)."
}

verify_url_health() {
    local url="$1"
    # Check if we've already tested this URL
    [[ -n "${URL_STATUS[$url]:-}" ]] && return

    if curl --max-time 10 -s -o /dev/null -L --head --fail "$url"; then
        log "$C_GREEN" "  [OK] $url"
        URL_STATUS["$url"]="OK"
    else
        log "$C_RED" "  [BROKEN] $url"
        URL_STATUS["$url"]="BROKEN"
    fi
}

run_link_checker() {
    log "$C_BLUE" "Starting URL health check..."

    # 1. Check critical, predefined URLs
    log "$C_CYAN" "Verifying critical application URLs..."
    for url in "${CRITICAL_URLS[@]}"; do
        verify_url_health "$url"
    done

    # 2. Scan configuration files for other URLs
    log "$C_CYAN" "Scanning REPL files for embedded URLs..."
    local exclusion_pattern
    exclusion_pattern=$(IFS=\|; echo "${EXCLUDED_DOMAINS[*]}")

    for file in "${REPL_FILES[@]}"; do
        [[ ! -f "$file" ]] && continue
        log "$C_CYAN" " -> In file: $file"
        
        # Using mapfile is faster than a while-read loop for processing lines
        mapfile -t urls < <(grep -Eo 'https?://[a-zA-Z0-9./?@&%_~#=-]+' "$file" | grep -Ev "($exclusion_pattern)" | sort -u)
        
        for url in "${urls[@]}"; do
            verify_url_health "$url"
        done
    done
    log "$C_GREEN" "URL health check finished."
}


# ---------- MAIN EXECUTION ----------

# --- Load External Config ---
CONFIG_FILE="$HOME/.ai_maintenance.conf"
[[ -f "$CONFIG_FILE" ]] && source "$CONFIG_FILE"

# --- Argument Parsing ---
[[ $# -eq 0 ]] && { RUN_BACKUP=1; RUN_CLEAN=1; RUN_CHECK=1; } # Default to full

while [[ $# -gt 0 ]]; do
    case "$1" in
        --backup) RUN_BACKUP=1 ;;
        --clean) RUN_CLEAN=1 ;;
        --check) RUN_CHECK=1 ;;
        --full) RUN_BACKUP=1; RUN_CLEAN=1; RUN_CHECK=1 ;;
        -f|--force) FORCE_MODE=1 ;;
        --no-color) C_GREEN=''; C_RED=''; C_YELLOW=''; C_BLUE=''; C_CYAN=''; C_NC='' ;;
        -h|--help) show_help; exit 0 ;;
        *) die "Unknown option: $1. Use --help for usage." ;;
    esac
    shift
done

# --- Start ---
setup_staging
log "$C_GREEN" "AI Environment Doctor - Initializing..."
check_dependencies

# --- Run Selected Actions ---
[[ "$RUN_BACKUP" -eq 1 ]] && create_backup_archive
[[ "$RUN_CLEAN" -eq 1 ]] && clean_directories
[[ "$RUN_CHECK" -eq 1 ]] && run_link_checker

# --- Final Summary ---
echo
log "$C_GREEN" "==================== FINAL REPORT ===================="
log "$C_CYAN" "Full execution log available at: ${LOG_FILE}"

declare -a broken_links=()
for url in "${!URL_STATUS[@]}"; do
    [[ "${URL_STATUS[$url]}" == "BROKEN" ]] && broken_links+=("$url")
done

if [[ ${#broken_links[@]} -gt 0 ]]; then
    log "$C_RED" "Found ${#broken_links[@]} broken link(s):"
    printf "  - %s\n" "${broken_links[@]}"
else
    log "$C_GREEN" "All checked links appear to be healthy."
fi
log "$C_GREEN" "===================================================="